---
layout:     post
title:      "随机采样方法"
subtitle:   "Sampling"
date:       2016-01-16 20:30:00
author:     "Beld"
header-img: "img/post-bg-engineer.jpg"
tags:
    - Machine learning
---

采样方法也叫Monte Carlo方法，比如计算π的投针实验。

##### 任务：

1. 采样与模拟： 产生体统的典型状态，比如噪声图像合成
    对很多系统，其状态由概率模型控制。这些约束可能是一些逻辑约束（8-皇后问题），也可能是一些宏观性质（如气体系统），也可能是统计观测（给定一些样例图像,合成有相同性质的图形）
2. 科学计算： 对高维空间进行积分
    Monte Carlo积分： 从分布产生n个样本，根据大数定律，可以用均值去近似期望
3. 贝叶斯推断
  * 比如给定图像，求图像的语义解释，我们需要对后验进行采样并保留多个解
4. 优化
  * 比如将一个求最小值的问题转化为求能量最小问题，这就是模拟退火算法基本思想

##### 优点：

1. 作为对确定性算法（输入确定，输出确定）的一个近似；
2. 不用参数模型就可以表示不确定性；
3. 以微小的近似误差来获取更高的计算效率

##### 但是怎么采样呢？

- 直接采样：对简单模型可用
- 概率积分变换
- 接受－拒绝采样，也叫Rejection Sampling
- 重要性采样
- 产生相关样本：马尔可夫链蒙特卡洛 MCMC


##### 接受拒绝采样

- 给定目标分布密度$$π(x)$$
- 找到建议密度（Proposal Density）$$q(x)$$和常数M，使得
  - 对$$q(x)$$采样比较容易
  - $$q(x)$$的形状接近$$π(x)$$，且 $$\pi \left( x \right) \le Mq\left( x \right) ,\forall x$$
<img src="http://i4.tietuku.com/b51492678e07b61d.png" alt="" width="245" />

- 采样过程 ［包络原则］
  - 1. 产生样本$$X\~ q\left( x \right)$$和$$U\sim Uniform\left[ 0,1 \right] $$
  - 2. 若$$U\le \pi \left( X \right) /Mq\left( X \right) $$， 则接受。
- 接受率，即采样的效率为$$1/M$$，对于高维问题，M可能很大，此时拒绝率接近100%

##### 重要性采样 Importance Sampling

- 对每个样本赋值一个重要性权重，$$w\left( x \right) =\quad \frac { \pi \left( x \right)  }{ q\left( x \right)  } $$

##### Markov Chain Monte Carlo

- 重要性采样和接受—拒绝采样都只有$$q(x)$$与 $$π(x)$$很相近似时才表现很好
- 在高维空间问题中,标准的采样方法会失败:   
  - 接受—拒绝采样:维数增高时,拒绝率 100%
  - 重要性采样:大多数的样本权重 0
- 对高维复杂问题,用马尔科夫链(Markov Chain) 产生一些列 *相关样本*,实现对分布的采样
- **基本思想： 设计一个马尔可夫链，使得其稳定概率为目标分布$$\pi\left( x \right)$$**

###### Markov Chain  马尔可夫链
- 马尔科夫链可以用状态转换图来表示
<img src="http://i8.tietuku.com/6c7a5575d2eac002.png" alt="" width="400" />
- 对一个马尔科夫链来说，未来状态只与当前t时刻有关，而与t时刻之前的历史状态无关（条件独立）
- 在这里我们只考虑每步转换概率相等的齐次马尔可夫链(homogeneous Markov chains)
- 马尔科夫链的一个很重要的性质是平稳分布(Stationary Distribution)。简单的说，主要统计性质不随时间而变的马尔科夫链就可以认为是平稳的。数学上有马氏链收敛定理，当步长n足够大时，一个非周期且任意状态联通的马氏链可以收敛到一个平稳分布π(x)。这个定理就是所有的MCMC方法的理论基础。
- 可逆的马氏链：满足细致平衡方程 $${ \pi  }_{ i }{ A }_{ ij }={ \pi  }_{ j }{ A }_{ ji }$$. 这里的 $${ \pi  }_{ t }$$ 表示马氏链在t时刻的边际分布，从而逆向马氏链一般不再是齐次的。
- 定理[细致平稳条件 Detailed Balance]：如果一个马尔可夫链，其转换矩阵不可约，而且满足关于$$\pi$$的细致平衡方程，那么$$\pi$$就是这个链的一个平稳分布。

##### The Metropolis-Hastings Algorithm

> MCMC方法最早由Metropolis（1954）给出，后来Metropolis的算法由Hastings改进，合称为M-H算法。M-H算法是MCMC的基础方法。由M-H算法演化出了许多新的抽样方法，包括目前在MCMC中最常用的Gibbs抽样也可以看做M-H算法的一个特例。

通常条件下，细致平稳条件是不成立的。不过，我们可以对其做一个改造，引入一个函数$$\alpha \left( i,j \right)$$，满足 $$0≤α(i,j)≤1$$，使得
<center>$${ \pi  }_{ i }{ A }_{ ij }\alpha \left( i,j \right)={ \pi  }_{ j }{ A }_{ ji }\alpha \left( j,i \right)$$</center>
那么，如何取得$$\alpha \left( i,j \right)$$呢？最简单的，依照对称性，我们可以取
<center>$$\alpha \left( i,j \right)={ \pi  }_{ j }{ A }_{ ji }, { \pi  }_{ i }{ A }_{ ij }=\alpha \left( j,i \right)$$</center>
这样就得到了新的具有平稳分布性质的马尔可夫链。

这里的$$\alpha \left( i,j \right)$$叫做接受率。如果接受率过小，会导致马氏链过多地拒绝状态转移，这样马氏链的收敛速度会很慢。因此，我们可以考虑放大$$\alpha \left( i,j \right)$$，使得方程中两个接受率中，最大的取1.这样拒绝率就可以表示为：
<center>$$α(i,j)=min\left(1,π(j)p(j,i)/π(i)p(i,j) \right)$$</center>
这就是M-H算法。 我们的讨论都是针对离散状态的，对连续状态的马尔科夫链依然有相同的结果。在连续状态中表示状态转移概率的项用条件概率密度代替，称为转移核。

M-H算法的步骤：

1. 构造合适的提议分布（Proposal distribution) $$q(⋅∣X_{t})$$在分布q中产生$$X_{0}$$；
2. 迭代下面的步骤：
    - 在$$q(⋅∣X_{t})$$中生成新样本Y；
    - 从均匀分布$$U(0,1)$$抽取随机数U；
    - 如果U满足$$U≤f(Y)q(X_{t}∣Y)/f(X_{t})q(Y∣X_{t})$$, 则令$$X_{t+1}=Y$$（转移到新状态），否则$$X_{t+1}=X_{t}$$（状态不变）。其中f是目标分布，也就是 我们需要进行抽样的后验分布；
    - 增加t值，进行下一步迭代。

通常高斯分布是一个好的建议，因为它满足任意状态都有非零概率。然而，高斯的方差也非常重要：小的话，就不够充分；大的话就会经常拒绝。

###### Gibbs采样

对高维的情况，由于接受率的存在，以上M-H算法效率不高，能否找到接受率为$$1$$的转移矩阵？  
Gibbs抽样是Stuart Geman和Donald Geman这两兄弟于1984年提出来的,可以看做MH算法当α=1的一个特例，用于目标分布为多元分布的情况。

假设在多元分布中所有的一元条件分布（每个分量对所有其它分量的条件分布，这个分布也叫做满条件分布）都是可以确定的。记$$m$$维随机向量$$X=(X_{1},X_{2},...,X_{m})′$$，$$X_{−i}$$表示X中去掉分量$$X_{i}后剩余的$$m-1$$维向量。那么一元条件分布就是$$f(X_{i}∣X_{−i})$$ 。Gibbs抽样就是在这$$m$$个条件分布中迭代产生样本。  
算法步骤如下:
1. 给出初值$$X(0)$$；
2. 对$$t=1,…,T$$，进行迭代：
    - 令$$x_{1}=X_1(t−1)$$；
    - 依次更新每一个分量，即对$$i=1,…,m$$，
        - (i)从$$f(X_{i}∣X_{−i}(t−1))$$中产生抽样X_{i}(t)；
        - (ii)更新$$x_{i}(t)=X_{i}(t)$$；
    - 令$$X(t)=(X_{1}(T),X_{2}(T),...,X_{m}(T))′$$(每个抽取的样本都被接受了)；
    - 更新$$t$$。

在这个算法里，对每一个状态$$t$$,$$X(t)$$的分量是依次更新的。这个分量更新的过程是在一元分布$$f(X_{i}∣X_{−i})$$中进行的，所以抽样是比较容易的。

###### 背后故事

斯坦福统计学教授Persi Diaconis是一位传奇式的人物。Diaconis14岁就成了一名魔术师,为了看懂数学家Feller的概率论著作，24岁时进入大学读书。他向《科学美国人》投稿介绍他的洗牌方法，在《科学美国人》上常年开设数学游戏专栏的著名数学科普作家马丁•加德纳给他写了推荐信去哈佛大学，当时哈佛的统计学家Mosteller 正在研究魔术，于是Diaconis成了Mosteller的学生。（对他这段传奇经历有兴趣的读者可以看一看统计学史话《女士品茶》）。 下面要讲的这个故事，是Diaconis 在他的文章The Markov Chain Monte Carlo Revolution中给出的破译犯人密码的例子。 一天，一位研究犯罪心理学的心理医生来到斯坦福拜访Diaconis。他带来了一个囚犯所写的密码信息。他希望Diaconis帮助他把这个密码中的信息找出来。 这个密码里的每个符号应该对应着某个字母，但是如何把这些字母准确地找出来呢？Diaconis和他的学生Marc采用了一种叫做MCMC（马尔科夫链蒙特卡洛）的方法解决了这个问题。这个MCMC方法就是这一节我们所要讨论的内容。
![](http://i8.tietuku.com/bf4cae500def56c4.jpg)
因为在文本中前后字母有依赖的关系，所以Marc利用前后字母的依赖关系，来描述整个密码文本中出现这些字符的概率模型。他用《战争与和平》作为标准的文本，统计一个字母到另一个字母的一步转移概率。然后他利用了M-H算法，在假设所有对应关系出现的可能性相等的前提下(也就是无信息先验的情况)，首先随机给出了字符和字母的对应关系。利用前边得到的转移概率，计算这种对应关系出现的概率p1。随机抽取两个字符，互换它们的对应关系，此时对应概率p2。如果P2>P1，接受新的对应关系；否则，抛一枚以P2/P1的概率出现正面的硬币，如果出现正面，则接受新的对应关系，否则依然保持旧有的对应关系。这就是MH算法的运用。当算法收敛时， 就会得到真实的对应关系。事实上，当算法运行了2000多步的时候，就得到了有意义的信息，一个混合了英语和西班牙语的文本段落。
![](http://i8.tietuku.com/8be3f4d014eb6d77.jpg)
