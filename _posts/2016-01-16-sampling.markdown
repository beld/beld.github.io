---
layout:     post
title:      "随机采样方法"
subtitle:   "Sampling"
date:       2016-01-16 20:30:00
author:     "Beld"
header-img: "img/post-bg-engineer.jpg"
tags:
    - Machine learning
---

采样方法也叫Monte Carlo方法，比如计算π的投针实验。

##### 任务：

1. 采样与模拟： 产生体统的典型状态，比如噪声图像合成
    对很多系统，其状态由概率模型控制。这些约束可能是一些逻辑约束（8-皇后问题），也可能是一些宏观性质（如气体系统），也可能是统计观测（给定一些样例图像,合成有相同性质的图形）
2. 科学计算： 对高维空间进行积分
    Monte Carlo积分： 从分布产生n个样本，根据大数定律，可以用均值去近似期望
3. 贝叶斯推断
  * 比如给定图像，求图像的语义解释，我们需要对后验进行采样并保留多个解
4. 优化
  * 比如将一个求最小值的问题转化为求能量最小问题，这就是模拟退火算法基本思想

##### 优点：

1. 作为对确定性算法（输入确定，输出确定）的一个近似；
2. 不用参数模型就可以表示不确定性；
3. 以微小的近似误差来获取更高的计算效率

##### 但是怎么采样呢？

- 直接采样：对简单模型可用
- 概率积分变换
- 接受－拒绝采样，也叫Rejection Sampling
- 重要性采样
- 产生相关样本：马尔可夫链蒙特卡洛 MCMC


##### 接受拒绝采样

- 给定目标分布密度$$π(x)$$
- 找到建议密度（Proposal Density）$$q(x)$$和常数M，使得
  - 对$$q(x)$$采样比较容易
  - $$q(x)$$的形状接近$$π(x)$$，且 $$\pi \left( x \right) \le Mq\left( x \right) ,\forall x$$
![  ](http://i4.tietuku.com/b51492678e07b61d.png)
- 采样过程 ［包络原则］
  - 1. 产生样本$$X\~ q\left( x \right)$$和$$U\sim Uniform\left[ 0,1 \right] $$
  - 2. 若$$U\le \pi \left( X \right) /Mq\left( X \right) $$， 则接受。
- 接受率，即采样的效率为$$1/M$$，对于高维问题，M可能很大，此时拒绝率接近100%

##### 重要性采样 Importance Sampling

- 对每个样本赋值一个重要性权重，$$w\left( x \right) =\quad \frac { \pi \left( x \right)  }{ q\left( x \right)  } $$

##### Markov Chain Monte Carlo

- 重要性采样和接受—拒绝采样都只有$$q(x)$$与 $$π(x)$$很相近似时才表现很好
- 在高维空间问题中,标准的采样方法会失败:   
  - 接受—拒绝采样:维数增高时,拒绝率 100%
  - 重要性采样:大多数的样本权重 0
- 对高维复杂问题,用马尔科夫链(Markov Chain) 产生一些列 *相关样本*,实现对分布的采样
- **基本思想： 设计一个马尔可夫链，使得其稳定概率为目标分布$$\pi\left( x \right)$$**

###### Markov Chain  马尔可夫链
- 马尔科夫链可以用状态转换图来表示
![  ](http://i8.tietuku.com/6c7a5575d2eac002.png)
- 对一个马尔科夫链来说，未来状态只与当前t时刻有关，而与t时刻之前的历史状态无关（条件独立）
- 在这里我们只考虑每步转换概率相等的齐次马尔可夫链(homogeneous Markov chains)
- 马尔科夫链的一个很重要的性质是平稳分布(Stationary Distribution)。简单的说，主要统计性质不随时间而变的马尔科夫链就可以认为是平稳的。数学上有马氏链收敛定理，当步长n足够大时，一个非周期且任意状态联通的马氏链可以收敛到一个平稳分布π(x)。这个定理就是所有的MCMC方法的理论基础。
- 可逆的马氏链：满足细致平衡方程 $${ \pi  }_{ i }{ A }_{ ij }={ \pi  }_{ j }{ A }_{ ji }$$. 这里的 $${ \pi  }_{ t }$$ 表示马氏链在t时刻的边际分布，从而逆向马氏链一般不再是齐次的。
- 定理[细致平稳条件 Detailed Balance]：如果一个马尔可夫链，其转换矩阵不可约，而且满足关于$$\pi$$的细致平衡方程，那么$$\pi$$就是这个链的一个平稳分布。

##### The Metropolis-Hastings Algorithm

> MCMC方法最早由Metropolis（1954）给出，后来Metropolis的算法由Hastings改进，合称为M-H算法。M-H算法是MCMC的基础方法。由M-H算法演化出了许多新的抽样方法，包括目前在MCMC中最常用的Gibbs抽样也可以看做M-H算法的一个特例。

通常条件下，细致平稳条件是不成立的。不过，我们可以对其做一个改造，引入一个函数$$\alpha \left( i,j \right)$$，满足 $$0≤α(i,j)≤1$$，使得
<center>$${ \pi  }_{ i }{ A }_{ ij }\alpha \left( i,j \right)={ \pi  }_{ j }{ A }_{ ji }\alpha \left( j,i \right)$$
那么，如何取得$$\alpha \left( i,j \right)$$呢？最简单的，依照对称性，我们可以取
<center>$$\alpha \left( i,j \right)={ \pi  }_{ j }{ A }_{ ji }$$，<center>$${ \pi  }_{ i }{ A }_{ ij }=\alpha \left( j,i \right)$$
这样就得到了新的具有平稳分布性质的马尔可夫链。

这里的$$\alpha \left( i,j \right)$$叫做接受率。如果接受率过小，会导致马氏链过多地拒绝状态转移，这样马氏链的收敛速度会很慢。因此，我们可以考虑放大$$\alpha \left( i,j \right)$$，使得方程中两个接受率中，最大的取1.这样拒绝率就可以表示为：
<center>$$α(i,j)=min\left(1,π(j)p(j,i)/π(i)p(i,j) \right)$$
这就是M-H算法。 我们的讨论都是针对离散状态的，对连续状态的马尔科夫链依然有相同的结果。在连续状态中表示状态转移概率的项用条件概率密度代替，称为转移核。

M-H算法的步骤：

1. 构造合适的提议分布（Proposal distribution) $$q(⋅∣X_{t})$$在分布q中产生$$X_{0}$$；
2. 迭代下面的步骤：
    - 在$$q(⋅∣X_{t})$$中生成新样本Y；
    - 从均匀分布$$U(0,1)$$抽取随机数U；
    - 如果U满足$$U≤f(Y)q(X_{t}∣Y)/f(X_{t})q(Y∣X_{t})$$, 则令$$X_{t+1}=Y$$（转移到新状态），否则$$X_{t+1}=X_{t}$$（状态不变）。其中f是目标分布，也就是 我们需要进行抽样的后验分布；
    - 增加t值，进行下一步迭代。

通常高斯分布是一个好的建议，因为它满足任意状态都有非零概率。然而，高斯的方差也非常重要：小的话，就不够充分；大的话就会经常拒绝。

###### Gibbs采样

对高维的情况，由于接受率的存在，以上M-H算法效率不高，
