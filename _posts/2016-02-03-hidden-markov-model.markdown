---
layout:     post
title:      "隐马尔科夫模型（二）"
subtitle:   ""
date:       2016-02-02 17:11:00
author:     "Beld"
header-img: "img/post-bg-ml.png"
tags:
    - Machine Learning
---

#### 隐马尔可夫模型的应用

给定一个观测序列$$x_1,x_2,x_3...$$，假定模型参数已知$$\theta =\{\pi,A,\psi\}$$，求给定的观测序列在此模型下实际发生的概率，比如数据的似然概率$$p(X|\theta)$$。这样如果我们有多个模型，就可以选择概率最高的。似然概率可以通过前向算法计算。这就是一个有监督学习问题，可以看作是推断步骤。相当于解码。

在得到数据似然的基础上，我们可以解决两种问题，滤波（Filtering）和平滑（Smoothing)。滤波是计算$$p(z_t|x_{1:t})$$，新估计的状态概率只根据之前的观测结果，可以通过前向算法计算。平滑是计算$$p(z_t|x_{1:T})$$，状态概率是基于所有的观测，包括未来的，可以通过向前向后算法计算。

给定一个观测序列$$x_1,x_2,x_3...$$，假定模型参数已知$$\theta =\{\pi,A,\psi\}$$，求最佳状态序列$$z_1,z_2,z_3...$$，可以通过维特比算法计算。

给定一个观测序列$$x_1,x_2,x_3...$$，求最佳模型参数$$\theta =\{\pi,A,\psi\}$$。这通常是最难的。可以通过最大期望EM算法计算或者Baum-Welch算法。

#### 向前向后算法 forward-backward 又叫 Baum-Welch算法

##### 向前算法 The Forward Algorithm



#### 维特比算法 Viterbi algorithm
待续
